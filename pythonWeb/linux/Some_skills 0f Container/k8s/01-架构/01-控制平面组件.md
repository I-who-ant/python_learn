# 控制平面组件

> kube-apiserver、etcd、scheduler、controller-manager

## 概述

【本文档是 Kubernetes 知识体系的一部分】

控制平面组件(Control Plane Components)是 Kubernetes 集群的大脑,负责做出全局决策(如调度)、检测和响应集群事件(如启动新 Pod)。这些组件通常运行在主节点上,共同维护集群的期望状态。

## 核心组件

### 1. kube-apiserver

#### 什么是 kube-apiserver

**API Server 是 Kubernetes 控制平面的前端**,是集群的统一入口。所有组件都通过它进行通信,它提供了 RESTful API 来操作集群资源。

#### 核心职责

| 职责 | 说明 |
|------|------|
| **API 服务** | 提供 REST API 接口,处理所有增删改查请求 |
| **认证授权** | 验证用户身份,检查操作权限(RBAC) |
| **准入控制** | 对请求进行验证和修改(Admission Controllers) |
| **数据持久化** | 将资源状态存储到 etcd |
| **Watch 通知** | 向客户端推送资源变更事件 |
| **代理功能** | 代理访问 kubelet、服务和节点 |

#### 工作流程

```
kubectl → 认证 → 授权 → 准入控制 → 验证 → 写入 etcd → 返回响应
          ↓        ↓          ↓         ↓        ↓
        身份验证  权限检查   策略检查   格式校验  持久化
```

#### 启动参数配置

```bash
# 查看 API Server 配置
kubectl -n kube-system get pod kube-apiserver-master -o yaml

# 常用启动参数
kube-apiserver \
  --advertise-address=192.168.1.100 \
  --etcd-servers=https://127.0.0.1:2379 \
  --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt \
  --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt \
  --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key \
  --secure-port=6443 \
  --authorization-mode=Node,RBAC \
  --enable-admission-plugins=NodeRestriction,PodSecurityPolicy \
  --service-cluster-ip-range=10.96.0.0/12 \
  --service-node-port-range=30000-32767 \
  --audit-log-path=/var/log/audit.log \
  --audit-log-maxage=30
```

#### 高可用配置

```yaml
# 多 API Server 实例 + 负载均衡
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - name: kube-apiserver
    image: k8s.gcr.io/kube-apiserver:v1.28.0
    command:
    - kube-apiserver
    - --advertise-address=$(POD_IP)
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-servers=https://etcd1:2379,https://etcd2:2379,https://etcd3:2379
    livenessProbe:
      httpGet:
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 15
      periodSeconds: 10
```

---

### 2. etcd

#### 什么是 etcd

**etcd 是一个高可用的分布式键值存储系统**,用于保存 Kubernetes 集群的所有数据。它是集群的"数据库",存储了集群的配置信息和状态数据。

#### 核心特性

| 特性 | 说明 |
|------|------|
| **强一致性** | 使用 Raft 协议保证数据一致性 |
| **高可用** | 支持多节点集群,容忍少数节点故障 |
| **Watch 机制** | 监听键值变化,实时推送事件 |
| **TTL 支持** | 键值可设置过期时间 |
| **事务支持** | 支持原子性操作 |

#### 存储结构

```
/registry/
├── pods/
│   └── default/
│       └── nginx-xxx
├── services/
│   └── default/
│       └── kubernetes
├── deployments/
│   └── default/
│       └── nginx-deployment
├── configmaps/
├── secrets/
└── ...
```

#### 集群配置

```bash
# 启动 etcd 集群 (3 节点示例)
# Node 1
etcd --name=etcd1 \
  --data-dir=/var/lib/etcd \
  --listen-client-urls=https://192.168.1.101:2379 \
  --advertise-client-urls=https://192.168.1.101:2379 \
  --listen-peer-urls=https://192.168.1.101:2380 \
  --initial-advertise-peer-urls=https://192.168.1.101:2380 \
  --initial-cluster=etcd1=https://192.168.1.101:2380,etcd2=https://192.168.1.102:2380,etcd3=https://192.168.1.103:2380 \
  --initial-cluster-state=new \
  --initial-cluster-token=etcd-cluster

# Node 2, Node 3 类似配置...
```

#### etcd 操作命令

```bash
# 设置环境变量
export ETCDCTL_API=3
export ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
export ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
export ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key
export ETCDCTL_ENDPOINTS=https://127.0.0.1:2379

# 查看集群成员
etcdctl member list

# 查看集群健康状态
etcdctl endpoint health

# 查看所有键
etcdctl get / --prefix --keys-only

# 查看 Pod 数据
etcdctl get /registry/pods/default/nginx-xxx

# 备份 etcd
etcdctl snapshot save /backup/etcd-snapshot.db

# 恢复 etcd
etcdctl snapshot restore /backup/etcd-snapshot.db \
  --data-dir=/var/lib/etcd-restore

# 碎片整理
etcdctl defrag

# 压缩历史版本
etcdctl compact $(etcdctl endpoint status --write-out="json" | jq -r '.[0].Status.header.revision')
```

---

### 3. kube-scheduler

#### 什么是 kube-scheduler

**Scheduler 是 Kubernetes 的资源调度器**,负责为新创建的 Pod 选择最合适的节点。它通过多种策略和算法,在满足资源需求的前提下,实现负载均衡和高可用。

#### 调度流程

```
1. Filtering (过滤)
   ↓
   找出所有可调度的节点
   (资源充足、污点容忍、节点选择器等)

2. Scoring (打分)
   ↓
   对可调度节点打分
   (资源均衡、亲和性、优先级等)

3. Binding (绑定)
   ↓
   选择分数最高的节点,将 Pod 绑定到该节点
```

#### 调度策略

```yaml
# 节点选择器
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeSelector:
    disktype: ssd
  containers:
  - name: nginx
    image: nginx

---
# 节点亲和性
apiVersion: v1
kind: Pod
metadata:
  name: with-node-affinity
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/hostname
            operator: In
            values:
            - node1
            - node2
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: zone
            operator: In
            values:
            - zone1
  containers:
  - name: nginx
    image: nginx

---
# Pod 亲和性与反亲和性
apiVersion: v1
kind: Pod
metadata:
  name: with-pod-affinity
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - cache
        topologyKey: kubernetes.io/hostname
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - web
          topologyKey: kubernetes.io/hostname
  containers:
  - name: nginx
    image: nginx

---
# 污点和容忍
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoSchedule"
  containers:
  - name: nginx
    image: nginx
```

#### 自定义调度器

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  schedulerName: my-scheduler  # 使用自定义调度器
  containers:
  - name: nginx
    image: nginx
```

---

### 4. kube-controller-manager

#### 什么是 kube-controller-manager

**Controller Manager 是控制器的集合**,运行各种控制器进程,负责监控集群状态并执行调谐操作,确保实际状态符合期望状态。

#### 内置控制器

| 控制器 | 职责 |
|--------|------|
| **Node Controller** | 监控节点健康状态,处理节点故障 |
| **Replication Controller** | 维护 Pod 副本数量 |
| **Endpoints Controller** | 填充 Endpoints 对象(关联 Service 和 Pod) |
| **Service Account Controller** | 为新命名空间创建默认 ServiceAccount |
| **Token Controller** | 为 ServiceAccount 创建 API 访问令牌 |
| **Namespace Controller** | 清理已删除命名空间的资源 |
| **Deployment Controller** | 管理 Deployment,控制滚动更新 |
| **StatefulSet Controller** | 管理有状态应用 |
| **DaemonSet Controller** | 确保每个节点运行指定 Pod |
| **Job Controller** | 管理一次性任务 |
| **CronJob Controller** | 管理定时任务 |

#### 控制循环原理

```go
// 伪代码示例
for {
    // 1. 获取期望状态
    desired := getDesiredState()

    // 2. 获取当前状态
    current := getCurrentState()

    // 3. 对比差异
    if current != desired {
        // 4. 执行调谐操作
        reconcile(desired, current)
    }

    // 5. 等待一段时间后重试
    sleep(interval)
}
```

#### 启动配置

```bash
kube-controller-manager \
  --bind-address=0.0.0.0 \
  --cluster-cidr=10.244.0.0/16 \
  --cluster-name=kubernetes \
  --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt \
  --cluster-signing-key-file=/etc/kubernetes/pki/ca.key \
  --kubeconfig=/etc/kubernetes/controller-manager.conf \
  --leader-elect=true \  # 高可用选举
  --node-cidr-mask-size=24 \
  --root-ca-file=/etc/kubernetes/pki/ca.crt \
  --service-account-private-key-file=/etc/kubernetes/pki/sa.key \
  --service-cluster-ip-range=10.96.0.0/12 \
  --use-service-account-credentials=true
```

---

### 5. cloud-controller-manager

#### 什么是 cloud-controller-manager

**Cloud Controller Manager 是云平台集成控制器**,将 Kubernetes 与云服务提供商(AWS、Azure、GCP 等)的 API 集成,管理云资源。

#### 核心控制器

| 控制器 | 职责 |
|--------|------|
| **Node Controller** | 检查云服务商确认节点是否被删除 |
| **Route Controller** | 在云平台配置路由 |
| **Service Controller** | 创建、更新、删除云负载均衡器 |
| **Volume Controller** | 创建、挂载、卸载云存储卷 |

#### 示例配置

```yaml
# 使用 AWS 云控制器的 LoadBalancer Service
apiVersion: v1
kind: Service
metadata:
  name: nginx
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 80
```

## 组件交互示例

### 创建 Deployment 的完整流程

```
1. kubectl → API Server
   POST /apis/apps/v1/namespaces/default/deployments

2. API Server → etcd
   存储 Deployment 对象

3. Deployment Controller (Watch API Server)
   检测到新 Deployment → 创建 ReplicaSet

4. ReplicaSet Controller (Watch API Server)
   检测到新 ReplicaSet → 创建 Pod

5. Scheduler (Watch API Server)
   检测到未调度的 Pod → 选择节点 → 绑定

6. kubelet (Watch API Server)
   检测到绑定到本节点的 Pod → 启动容器
```

## 最佳实践

### 1. API Server 优化

```bash
# 限流配置
--max-requests-inflight=400
--max-mutating-requests-inflight=200

# 审计日志
--audit-policy-file=/etc/kubernetes/audit-policy.yaml
--audit-log-path=/var/log/audit.log
--audit-log-maxage=30
--audit-log-maxbackup=10
--audit-log-maxsize=100

# 监控指标
curl -k https://localhost:6443/metrics
```

### 2. etcd 性能优化

```bash
# 定期备份
0 2 * * * etcdctl snapshot save /backup/etcd-$(date +\%Y\%m\%d).db

# 监控关键指标
- 磁盘 IOPS (建议 SSD)
- 网络延迟 (建议 < 10ms)
- 数据库大小 (定期压缩)

# 告警阈值
- Leader 变更频繁
- 慢查询 (> 100ms)
- 数据库大小接近配额
```

### 3. Scheduler 调优

```yaml
# 自定义调度配置
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
profiles:
- schedulerName: default-scheduler
  plugins:
    score:
      enabled:
      - name: NodeResourcesBalancedAllocation
        weight: 1
      - name: ImageLocality
        weight: 1
```

### 4. Controller Manager 配置

```bash
# 控制器并发数
--concurrent-deployment-syncs=5
--concurrent-replicaset-syncs=5
--concurrent-statefulset-syncs=5

# 节点监控周期
--node-monitor-period=5s
--node-monitor-grace-period=40s
```

## 故障排查

### API Server 问题

```bash
# 查看日志
kubectl logs -n kube-system kube-apiserver-master

# 检查证书
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout

# 测试连接
curl -k https://localhost:6443/healthz
```

### etcd 问题

```bash
# 检查集群健康
etcdctl endpoint health --cluster

# 查看告警
etcdctl alarm list

# 查看慢查询
etcdctl check perf

# 数据一致性检查
etcdctl endpoint status --write-out=table
```

### Scheduler 问题

```bash
# 查看调度失败原因
kubectl describe pod <pod-name>

# 查看 Scheduler 日志
kubectl logs -n kube-system kube-scheduler-master

# 查看调度事件
kubectl get events --sort-by='.lastTimestamp'
```

## 常见问题

### Q1: API Server 无法访问怎么办?

**A**: 排查步骤:
```bash
# 1. 检查进程是否运行
ps aux | grep kube-apiserver

# 2. 检查端口监听
netstat -tlnp | grep 6443

# 3. 检查证书有效期
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout | grep "Not After"

# 4. 检查 etcd 连接
etcdctl endpoint health

# 5. 查看日志
journalctl -u kube-apiserver -f
```

### Q2: etcd 数据库空间满了怎么办?

**A**:
```bash
# 1. 检查当前大小
etcdctl endpoint status --write-out=table

# 2. 压缩历史版本
REV=$(etcdctl endpoint status --write-out="json" | jq -r '.[0].Status.header.revision')
etcdctl compact $REV

# 3. 碎片整理
etcdctl defrag

# 4. 增加配额 (重启 etcd 生效)
--quota-backend-bytes=8589934592  # 8GB
```

### Q3: Pod 一直处于 Pending 状态?

**A**: 检查调度失败原因:
```bash
# 查看事件
kubectl describe pod <pod-name>

# 常见原因:
# - 资源不足: Insufficient cpu/memory
# - 节点选择器不匹配: node(s) didn't match node selector
# - 污点不容忍: node(s) had taint that the pod didn't tolerate
# - 亲和性规则: node(s) didn't match pod affinity rules
```

### Q4: 如何实现控制平面高可用?

**A**:
```bash
# 1. etcd 集群 (3/5/7 节点)
# 2. 多 API Server + 负载均衡
# 3. Controller Manager Leader 选举
# 4. Scheduler Leader 选举

# 负载均衡配置 (HAProxy)
frontend k8s-api
    bind *:6443
    mode tcp
    option tcplog
    default_backend k8s-api-backend

backend k8s-api-backend
    mode tcp
    balance roundrobin
    server master1 192.168.1.101:6443 check
    server master2 192.168.1.102:6443 check
    server master3 192.168.1.103:6443 check
```

## 总结

- ✅ **kube-apiserver**: 集群网关,所有组件的统一入口
- ✅ **etcd**: 分布式存储,集群数据的唯一来源
- ✅ **kube-scheduler**: 资源调度器,为 Pod 选择合适节点
- ✅ **kube-controller-manager**: 控制器管理器,维护集群期望状态
- ✅ **cloud-controller-manager**: 云平台集成,管理云资源
- ✅ **高可用架构**: 多主节点 + 选举机制 + 负载均衡
- ✅ **故障排查**: 日志分析、健康检查、证书验证

## 参考资源

- [kube-apiserver 官方文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/)
- [etcd 官方文档](https://etcd.io/docs/)
- [kube-scheduler 文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/)
- [kube-controller-manager 文档](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/)
- [Kubernetes 组件架构](https://kubernetes.io/docs/concepts/overview/components/)

---

*更新日期: 2025-12-03*
