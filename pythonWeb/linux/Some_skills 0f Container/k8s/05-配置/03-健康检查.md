# 健康检查

> livenessProbe、readinessProbe、startupProbe

## 概述

【本文档是 Kubernetes 知识体系的一部分】

**健康检查(Health Checks)是 Kubernetes 自动化运维的核心能力之一**。通过配置探针(Probes),kubelet 可以自动检测容器的健康状态,并在出现问题时采取相应措施,如重启容器或从服务中摘除,从而提高应用的可用性和可靠性。

## 核心概念

### 什么是健康检查

Kubernetes 提供三种探针来检查容器的健康状态:

| 探针类型 | 作用 | 失败后果 |
|---------|------|---------|
| **livenessProbe** | 检查容器是否存活 | 重启容器 |
| **readinessProbe** | 检查容器是否就绪 | 从 Service 移除 |
| **startupProbe** | 检查容器是否启动完成 | 延迟其他探针执行 |

### 探针工作流程

```
容器启动
   ↓
startupProbe (如果配置)
   ↓ 成功
   ├────────────────────────┐
   │                        │
   ▼                        ▼
livenessProbe         readinessProbe
   │                        │
   ↓ 失败                    ↓ 失败
重启容器                 从 Service 移除
```

### 为什么需要健康检查

| 问题场景 | 解决方案 |
|---------|---------|
| **容器进程存在但无响应** | livenessProbe 检测并重启 |
| **应用启动慢** | startupProbe 避免过早检查 |
| **依赖服务未就绪** | readinessProbe 延迟流量接入 |
| **应用内部死锁** | livenessProbe 自动恢复 |
| **滚动更新期间流量丢失** | readinessProbe 确保就绪后接入流量 |

---

## 探针类型

### 1. HTTP GET 探针

通过 HTTP GET 请求检查健康状态。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: http-probe
spec:
  containers:
  - name: web
    image: nginx:1.21
    livenessProbe:
      httpGet:
        path: /healthz
        port: 80
        httpHeaders:
        - name: Custom-Header
          value: Awesome
        scheme: HTTP  # HTTP 或 HTTPS
      initialDelaySeconds: 15
      periodSeconds: 10
      timeoutSeconds: 1
      successThreshold: 1
      failureThreshold: 3
```

#### 判断标准

| HTTP 状态码 | 结果 |
|-----------|------|
| **200-399** | 成功 |
| **其他** | 失败 |

### 2. TCP Socket 探针

通过 TCP 连接检查端口是否可达。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: tcp-probe
spec:
  containers:
  - name: redis
    image: redis:7
    livenessProbe:
      tcpSocket:
        port: 6379
      initialDelaySeconds: 5
      periodSeconds: 10
```

**适用场景**:
- 非 HTTP 服务(数据库、缓存)
- 简单的端口检查

### 3. Exec 探针

在容器内执行命令,根据退出码判断健康状态。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: exec-probe
spec:
  containers:
  - name: app
    image: busybox:1.35
    command: ["/bin/sh", "-c", "touch /tmp/healthy; sleep 300"]
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
```

#### 判断标准

| 退出码 | 结果 |
|-------|------|
| **0** | 成功 |
| **非0** | 失败 |

### 4. gRPC 探针(Kubernetes 1.24+)

通过 gRPC 健康检查协议检查服务。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: grpc-probe
spec:
  containers:
  - name: grpc-service
    image: mygrpc:1.0
    livenessProbe:
      grpc:
        port: 9090
        service: myservice  # 可选,默认为 ""
      initialDelaySeconds: 10
      periodSeconds: 5
```

**要求**:
- 服务需实现 gRPC 健康检查协议
- [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)

---

## 三种探针详解

### 1. livenessProbe(存活探针)

#### 作用

检查容器是否存活,如果失败则重启容器。

#### 使用场景

- 应用死锁或卡死
- 内存泄漏导致 OOM 前自动重启
- 应用进程存在但无法处理请求

#### 配置示例

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: liveness-demo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: liveness
  template:
    metadata:
      labels:
        app: liveness
    spec:
      containers:
      - name: app
        image: nginx:1.21
        ports:
        - containerPort: 80
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 15   # 初始延迟
          periodSeconds: 10          # 检查间隔
          timeoutSeconds: 1          # 超时时间
          successThreshold: 1        # 成功阈值
          failureThreshold: 3        # 失败阈值
```

#### 重启策略

```yaml
spec:
  restartPolicy: Always   # Always、OnFailure、Never
```

#### 查看重启记录

```bash
# 查看 Pod 重启次数
kubectl get pods

# 查看重启原因
kubectl describe pod liveness-demo-xxx

# 查看容器日志(包含重启前的日志)
kubectl logs liveness-demo-xxx --previous
```

---

### 2. readinessProbe(就绪探针)

#### 作用

检查容器是否就绪,如果失败则从 Service 的 Endpoints 中移除,停止接收流量。

#### 使用场景

- 应用启动阶段,需要加载数据或预热
- 依赖外部服务,等待依赖就绪
- 滚动更新时,确保新版本就绪后才接入流量
- 临时过载,暂停接收新请求

#### 配置示例

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: readiness-demo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: readiness
  template:
    metadata:
      labels:
        app: readiness
    spec:
      containers:
      - name: app
        image: myapp:1.0
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 3
```

#### 与 Service 集成

```yaml
---
# Service
apiVersion: v1
kind: Service
metadata:
  name: readiness-service
spec:
  selector:
    app: readiness
  ports:
  - port: 80
    targetPort: 8080
```

**流量控制逻辑**:
```
1. readinessProbe 失败
   ↓
2. Pod 从 Endpoints 移除
   ↓
3. Service 不再转发流量到该 Pod
   ↓
4. readinessProbe 恢复
   ↓
5. Pod 重新加入 Endpoints
   ↓
6. Service 恢复转发流量
```

#### 查看 Endpoints

```bash
# 查看 Service Endpoints
kubectl get endpoints readiness-service

# 详细信息
kubectl describe endpoints readiness-service

# 输出示例
Name:         readiness-service
Namespace:    default
Subsets:
  Addresses:    10.244.1.5,10.244.2.6  # 就绪的 Pod
  NotReadyAddresses:  10.244.3.7       # 未就绪的 Pod
  Ports:
    Name  Port  Protocol
    ----  ----  --------
    http  8080  TCP
```

---

### 3. startupProbe(启动探针)

#### 作用

检查容器是否启动完成,在 startupProbe 成功之前,livenessProbe 和 readinessProbe 不会执行。

#### 使用场景

- 应用启动慢(大型 Java 应用、数据加载)
- 避免 livenessProbe 过早检查导致重启
- 给予足够的启动时间

#### 配置示例

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: startup-demo
spec:
  containers:
  - name: java-app
    image: openjdk:11
    ports:
    - containerPort: 8080
    # 启动探针:最多等待 300 秒(30 * 10)
    startupProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      failureThreshold: 30  # 30 * 10s = 300s
    # 启动成功后才执行存活探针
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      periodSeconds: 10
      failureThreshold: 3
    # 启动成功后才执行就绪探针
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
```

#### 与其他探针的关系

```
容器启动
   ↓
startupProbe 执行(每 10 秒一次,最多 30 次)
   │
   ├─ 成功 → 停止 startupProbe → 开始执行 livenessProbe 和 readinessProbe
   │
   └─ 失败 30 次 → 重启容器
```

---

## 探针参数详解

### 通用参数

```yaml
livenessProbe:
  httpGet:
    path: /healthz
    port: 8080
  # 时间参数(单位:秒)
  initialDelaySeconds: 10   # 容器启动后多久开始探测
  periodSeconds: 5          # 探测间隔
  timeoutSeconds: 1         # 探测超时时间
  successThreshold: 1       # 从失败到成功需要的连续成功次数
  failureThreshold: 3       # 从成功到失败需要的连续失败次数

  # 终止宽限期
  terminationGracePeriodSeconds: 30  # Pod 删除时的优雅终止时间
```

### 参数说明

| 参数 | 默认值 | 说明 |
|-----|-------|------|
| **initialDelaySeconds** | 0 | 容器启动后延迟多久开始探测 |
| **periodSeconds** | 10 | 探测频率 |
| **timeoutSeconds** | 1 | 单次探测超时时间 |
| **successThreshold** | 1 | 失败→成功需要的连续成功次数 |
| **failureThreshold** | 3 | 成功→失败需要的连续失败次数 |

### 参数计算

#### livenessProbe 总等待时间

```bash
总等待时间 = initialDelaySeconds + (periodSeconds * failureThreshold)

# 示例
initialDelaySeconds: 10
periodSeconds: 5
failureThreshold: 3

总等待时间 = 10 + (5 * 3) = 25 秒
```

#### startupProbe 最大启动时间

```bash
最大启动时间 = initialDelaySeconds + (periodSeconds * failureThreshold)

# 示例
initialDelaySeconds: 0
periodSeconds: 10
failureThreshold: 30

最大启动时间 = 0 + (10 * 30) = 300 秒
```

---

## 实战案例

### 案例 1: Web 应用健康检查

```yaml
---
# 应用 Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx:1.21
        ports:
        - containerPort: 80
        # 存活探针:检查主页
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 3
        # 就绪探针:检查就绪接口
        readinessProbe:
          httpGet:
            path: /ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          failureThreshold: 2

---
# Service
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 80
  type: LoadBalancer
```

#### 实现健康检查接口

```nginx
# nginx 配置
server {
    listen 80;

    # 主页
    location / {
        root /usr/share/nginx/html;
        index index.html;
    }

    # 健康检查接口
    location /ready {
        access_log off;
        return 200 "ready\n";
        add_header Content-Type text/plain;
    }
}
```

### 案例 2: 数据库健康检查

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mysql-pod
spec:
  containers:
  - name: mysql
    image: mysql:8.0
    env:
    - name: MYSQL_ROOT_PASSWORD
      value: password
    ports:
    - containerPort: 3306
    # 存活探针:TCP 检查
    livenessProbe:
      tcpSocket:
        port: 3306
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    # 就绪探针:执行 SQL 查询
    readinessProbe:
      exec:
        command:
        - sh
        - -c
        - "mysqladmin ping -u root -p$MYSQL_ROOT_PASSWORD"
      initialDelaySeconds: 10
      periodSeconds: 5
      timeoutSeconds: 1
```

### 案例 3: 慢启动应用

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: java-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: java
  template:
    metadata:
      labels:
        app: java
    spec:
      containers:
      - name: spring-boot
        image: myapp:1.0
        ports:
        - containerPort: 8080
        # 启动探针:给予 5 分钟启动时间
        startupProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 0
          periodSeconds: 10
          failureThreshold: 30  # 10s * 30 = 300s = 5min
        # 存活探针:启动成功后每 10 秒检查
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # 就绪探针:检查应用就绪
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
```

### 案例 4: Redis 主从健康检查

```yaml
---
# Redis Master
apiVersion: v1
kind: Pod
metadata:
  name: redis-master
spec:
  containers:
  - name: redis
    image: redis:7
    ports:
    - containerPort: 6379
    livenessProbe:
      tcpSocket:
        port: 6379
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      exec:
        command:
        - sh
        - -c
        - "redis-cli ping | grep PONG"
      initialDelaySeconds: 5
      periodSeconds: 5

---
# Redis Slave
apiVersion: v1
kind: Pod
metadata:
  name: redis-slave
spec:
  containers:
  - name: redis
    image: redis:7
    command: ["redis-server", "--slaveof", "redis-master", "6379"]
    ports:
    - containerPort: 6379
    livenessProbe:
      tcpSocket:
        port: 6379
      initialDelaySeconds: 30
      periodSeconds: 10
    readinessProbe:
      exec:
        command:
        - sh
        - -c
        - |
          redis-cli info replication | grep master_link_status:up
      initialDelaySeconds: 10
      periodSeconds: 5
```

---

## 最佳实践

### 1. 合理设置初始延迟

```yaml
# ✅ 好的做法:根据应用启动时间设置
spec:
  containers:
  - name: app
    image: myapp:1.0
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 30  # 应用需要 20-30 秒启动
      periodSeconds: 10

# ❌ 不推荐:延迟过短导致频繁重启
spec:
  containers:
  - name: app
    image: myapp:1.0
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 0  # 应用还未启动就开始检查
```

### 2. 慢启动应用使用 startupProbe

```yaml
# ✅ 推荐:使用 startupProbe 避免过早重启
spec:
  containers:
  - name: java-app
    image: large-java-app:1.0
    startupProbe:
      httpGet:
        path: /health
        port: 8080
      periodSeconds: 10
      failureThreshold: 30  # 最多等待 300 秒
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      periodSeconds: 10
      failureThreshold: 3

# ❌ 不推荐:只用 livenessProbe,initialDelaySeconds 过大
spec:
  containers:
  - name: java-app
    image: large-java-app:1.0
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
      initialDelaySeconds: 300  # 启动快时浪费时间
      periodSeconds: 10
```

### 3. 区分 liveness 和 readiness 检查

```yaml
# ✅ 好的做法:区分两种检查
spec:
  containers:
  - name: app
    image: myapp:1.0
    livenessProbe:
      httpGet:
        path: /health    # 检查应用存活
        port: 8080
      periodSeconds: 10
    readinessProbe:
      httpGet:
        path: /ready     # 检查应用就绪(包含依赖检查)
        port: 8080
      periodSeconds: 5

# ❌ 不推荐:两个探针使用相同接口
spec:
  containers:
  - name: app
    image: myapp:1.0
    livenessProbe:
      httpGet:
        path: /health
        port: 8080
    readinessProbe:
      httpGet:
        path: /health  # 相同接口,无法区分问题
        port: 8080
```

### 4. readinessProbe 不应检查外部依赖

```yaml
# ✅ 好的做法:readiness 只检查自身
readinessProbe:
  httpGet:
    path: /ready
    port: 8080

# /ready 实现(Go 示例)
func readyHandler(w http.ResponseWriter, r *http.Request) {
    // 检查自身服务是否就绪
    if !app.IsReady() {
        w.WriteHeader(http.StatusServiceUnavailable)
        return
    }
    w.WriteHeader(http.StatusOK)
}

# ❌ 不推荐:readiness 检查外部依赖
# 外部依赖故障会导致所有 Pod 都 NotReady
func readyHandler(w http.ResponseWriter, r *http.Request) {
    // 检查数据库连接
    if !db.Ping() {
        w.WriteHeader(http.StatusServiceUnavailable)
        return
    }
    w.WriteHeader(http.StatusOK)
}
```

### 5. 设置合理的超时和阈值

```yaml
# ✅ 推荐配置
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10       # 每 10 秒检查一次
  timeoutSeconds: 5       # 5 秒超时(考虑网络延迟)
  failureThreshold: 3     # 失败 3 次才重启(避免误判)

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5        # 更频繁检查
  timeoutSeconds: 3
  failureThreshold: 2     # 更快从服务摘除
```

### 6. 避免探针过于复杂

```yaml
# ✅ 好的做法:简单快速的检查
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  timeoutSeconds: 1

# /health 实现(快速返回)
func healthHandler(w http.ResponseWriter, r *http.Request) {
    w.WriteHeader(http.StatusOK)
    w.Write([]byte("OK"))
}

# ❌ 不推荐:复杂耗时的检查
livenessProbe:
  exec:
    command:
    - sh
    - -c
    - "curl http://api.example.com && check-database && verify-cache"
  timeoutSeconds: 10  # 超时时间长,影响故障恢复
```

### 7. 生产环境同时配置三种探针

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: production-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:1.0
        # 1. 启动探针:处理慢启动
        startupProbe:
          httpGet:
            path: /health
            port: 8080
          periodSeconds: 10
          failureThreshold: 30
        # 2. 存活探针:自动重启故障容器
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        # 3. 就绪探针:流量控制
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 2
```

---

## 监控和调试

### 查看探针状态

```bash
# 查看 Pod 状态
kubectl get pods

# 详细信息(包含探针事件)
kubectl describe pod myapp-xxx

# 示例输出
Events:
  Type     Reason     Age   From               Message
  ----     ------     ----  ----               -------
  Warning  Unhealthy  30s   kubelet            Liveness probe failed: HTTP probe failed with statuscode: 500
  Warning  Unhealthy  20s   kubelet            Readiness probe failed: Get "http://10.244.1.5:8080/ready": dial tcp 10.244.1.5:8080: connect: connection refused
```

### 查看 Pod 条件

```bash
kubectl get pod myapp-xxx -o jsonpath='{.status.conditions[*]}'

# 输出
{
  "type": "Ready",
  "status": "False",
  "reason": "ContainersNotReady"
}
```

### 手动测试探针

```bash
# 进入容器测试 HTTP 探针
kubectl exec -it myapp-xxx -- curl http://localhost:8080/health

# 测试 TCP 探针
kubectl exec -it myapp-xxx -- nc -zv localhost 6379

# 测试 Exec 探针
kubectl exec -it myapp-xxx -- cat /tmp/healthy
```

### 查看 Endpoints

```bash
# 查看哪些 Pod 就绪
kubectl get endpoints myapp-service

# 输出
NAME          ENDPOINTS                       AGE
myapp-service 10.244.1.5:8080,10.244.2.6:8080 5m
```

### Prometheus 监控

```bash
# 关键指标
# - kube_pod_container_status_ready
# - kube_pod_container_status_restarts_total
# - probe_success (Blackbox Exporter)
# - probe_duration_seconds

# PromQL 示例
# Pod 重启次数
rate(kube_pod_container_status_restarts_total[5m])

# Pod 未就绪数量
count(kube_pod_status_ready{condition="false"})

# 探针成功率
avg(probe_success) by (pod)
```

---

## 故障排查

### 问题 1: Pod 频繁重启

```bash
# 症状
kubectl get pods
NAME        READY   STATUS    RESTARTS   AGE
myapp-xxx   1/1     Running   15         5m

# 排查
kubectl describe pod myapp-xxx

# 原因
Liveness probe failed: HTTP probe failed with statuscode: 503

# 解决方案
# 1. 增加 initialDelaySeconds
# 2. 增加 failureThreshold
# 3. 检查应用日志
kubectl logs myapp-xxx

# 4. 调整探针配置
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 60    # 增加初始延迟
  periodSeconds: 10
  failureThreshold: 5        # 增加失败阈值
```

### 问题 2: Pod 未加入 Service

```bash
# 症状
kubectl get endpoints myapp-service
NAME          ENDPOINTS   AGE
myapp-service <none>      5m

# 排查
kubectl describe pod myapp-xxx

# 原因
Readiness probe failed: Get "http://10.244.1.5:8080/ready": dial tcp 10.244.1.5:8080: connect: connection refused

# 解决方案
# 1. 检查端口是否正确
# 2. 检查应用是否监听该端口
kubectl exec -it myapp-xxx -- netstat -tuln | grep 8080

# 3. 检查就绪接口是否实现
kubectl exec -it myapp-xxx -- curl http://localhost:8080/ready

# 4. 调整 readinessProbe 配置
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 10  # 增加延迟
  periodSeconds: 5
```

### 问题 3: 启动慢导致 CrashLoopBackOff

```bash
# 症状
kubectl get pods
NAME        READY   STATUS             RESTARTS   AGE
myapp-xxx   0/1     CrashLoopBackOff   5          5m

# 排查
kubectl describe pod myapp-xxx

# 原因
Liveness probe failed: Get "http://10.244.1.5:8080/health": dial tcp 10.244.1.5:8080: connect: connection refused
Container myapp failed liveness probe, will be restarted

# 解决方案
# 使用 startupProbe
startupProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 0
  periodSeconds: 10
  failureThreshold: 60  # 最多等待 600 秒
```

### 问题 4: 探针超时

```bash
# 症状
Readiness probe failed: Get "http://10.244.1.5:8080/ready": context deadline exceeded (Client.Timeout exceeded)

# 原因
# - 探针超时时间过短
# - 应用响应慢

# 解决方案
# 1. 增加超时时间
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  timeoutSeconds: 5  # 增加到 5 秒

# 2. 优化应用性能
# 3. 简化健康检查逻辑
```

---

## 常见问题

### Q1: livenessProbe 和 readinessProbe 有什么区别?

**A**:

| 探针 | 失败后果 | 使用场景 |
|-----|---------|---------|
| **livenessProbe** | 重启容器 | 应用死锁、卡死 |
| **readinessProbe** | 从 Service 移除 | 应用启动中、临时过载 |

### Q2: 什么时候需要 startupProbe?

**A**:
```yaml
# 需要 startupProbe 的场景:
# 1. 应用启动时间 > 30 秒
# 2. 启动时间不确定
# 3. 避免 livenessProbe 过早检查

# 示例:大型 Java 应用
startupProbe:
  httpGet:
    path: /health
    port: 8080
  periodSeconds: 10
  failureThreshold: 60  # 最多等待 10 分钟
```

### Q3: 探针检查失败会立即重启容器吗?

**A**: 不会,需要连续失败 `failureThreshold` 次才会触发操作。

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  periodSeconds: 10
  failureThreshold: 3  # 连续失败 3 次才重启

# 时间线:
# T=0s:  第 1 次失败
# T=10s: 第 2 次失败
# T=20s: 第 3 次失败 → 触发重启
```

### Q4: 如何避免滚动更新时流量丢失?

**A**:
```yaml
# 配置 readinessProbe 和优雅终止
spec:
  containers:
  - name: app
    image: myapp:1.0
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 15"]
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
  terminationGracePeriodSeconds: 30

# 工作流程:
# 1. 新 Pod 启动,readinessProbe 成功后加入 Service
# 2. 旧 Pod 收到 SIGTERM,执行 preStop(等待 15 秒)
# 3. 旧 Pod 从 Service 移除
# 4. 等待现有请求处理完毕
# 5. 终止容器
```

### Q5: HTTP 探针应该返回什么状态码?

**A**:
```go
// ✅ 推荐:明确的状态码
func healthHandler(w http.ResponseWriter, r *http.Request) {
    if isHealthy() {
        w.WriteHeader(http.StatusOK)  // 200
        return
    }
    w.WriteHeader(http.StatusServiceUnavailable)  // 503
}

// Kubernetes 判断:
// - 200-399: 成功
// - 其他: 失败
```

---

## 总结

- ✅ **livenessProbe**: 检查容器存活,失败则重启容器
- ✅ **readinessProbe**: 检查容器就绪,失败则从 Service 移除
- ✅ **startupProbe**: 处理慢启动应用,避免过早检查
- ✅ **探针类型**: HTTP GET、TCP Socket、Exec、gRPC
- ✅ **最佳实践**: 合理设置初始延迟、超时和阈值,区分 liveness 和 readiness
- ✅ **生产建议**: 同时配置三种探针,简化健康检查逻辑
- ✅ **监控**: 关注重启次数、就绪状态、探针成功率

## 参考资源

- [Configure Liveness, Readiness and Startup Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
- [Pod Lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/)
- [Container Probes](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes)
- [gRPC Health Checking Protocol](https://github.com/grpc/grpc/blob/master/doc/health-checking.md)

---

*更新日期: 2025-12-03*
